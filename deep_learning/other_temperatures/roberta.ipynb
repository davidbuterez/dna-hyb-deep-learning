{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from transformers import RobertaTokenizerFast, RobertaModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, roc_curve, matthews_corrcoef, plot_confusion_matrix, average_precision_score, auc, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data, max_len, with_yield=True):\n",
    "        self.data = pd.DataFrame(data, columns=['Seq1', 'Seq2', 'Yield'])  # pandas dataframe\n",
    "        self.data['Yield'] = self.data['Yield'] * 100\n",
    "        #Initialize the tokenizer\n",
    "        self.tokenizer = RobertaTokenizerFast.from_pretrained(\"tokenizer\", max_len=64)\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.with_yield = with_yield \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Selecting sequence1 and sequence2 at the specified index in the data frame\n",
    "        seq1 = str(self.data.loc[index, 'Seq1'])\n",
    "        seq2 = str(self.data.loc[index, 'Seq2'])\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_pair = self.tokenizer(seq1, seq2, \n",
    "                                      padding='max_length',         # Pad to max_length\n",
    "                                      truncation=True,              # Truncate to max_length\n",
    "                                      max_length=self.max_len,  \n",
    "                                      return_tensors='pt')          # Return torch.Tensor objects\n",
    "\n",
    "        token_ids = encoded_pair['input_ids'].squeeze(0)            # tensor of token ids\n",
    "        attn_masks = encoded_pair['attention_mask'].squeeze(0)      # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
    "#         token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
    "\n",
    "        if self.with_yield:  # True if the dataset has yields\n",
    "            yld = self.data.loc[index, 'Yield']\n",
    "            return token_ids, attn_masks, yld  \n",
    "        else:\n",
    "            return token_ids, attn_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaFineTuner(pl.LightningModule):\n",
    "    def __init__(self, roberta_model_path='.', freeze_roberta=False, hidden_size=256, lr = 1e-5):\n",
    "        super(RoBERTaFineTuner, self).__init__()\n",
    "        self.roberta_layer = RobertaModel.from_pretrained(roberta_model_path)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "        self.out_predictions = []\n",
    "    \n",
    "        # Freeze bert layers and only train the classification layer weights\n",
    "        if freeze_roberta:\n",
    "            for p in self.roberta_layer.parameters():\n",
    "                p.requires_grad = False\n",
    "                \n",
    "        # Regression layer\n",
    "        self.hidden_layer = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, input_ids, attn_masks):\n",
    "        # Feeding the inputs to the RoBERTa-based model to obtain contextualized representations\n",
    "        roberta_out = self.roberta_layer(input_ids, attn_masks)\n",
    "        last_hidden_state, pooler_output = roberta_out['last_hidden_state'], roberta_out['pooler_output']\n",
    "        return self.hidden_layer(self.dropout(pooler_output))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        token_ids, attn_masks, yields = batch\n",
    "        out = self(token_ids, attn_masks)\n",
    "        loss = F.mse_loss(torch.squeeze(out), yields)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.lr, weight_decay=1e-2)\n",
    "        return optimizer\n",
    "            \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        token_ids, attn_masks, yields = batch\n",
    "        val_out = self(token_ids, attn_masks)\n",
    "        val_loss = F.mse_loss(torch.squeeze(val_out), yields)\n",
    "        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return val_loss\n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        token_ids, attn_masks, yields = batch\n",
    "        test_out = self(token_ids, attn_masks)\n",
    "        self.out_predictions.append(test_out)\n",
    "        test_loss = F.mse_loss(torch.squeeze(test_out), yields)\n",
    "        self.log('test_loss', test_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path) as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_json('splits/train.json')\n",
    "val = read_json('splits/val.json')\n",
    "test = read_json('splits/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('splits/y_test.npy')\n",
    "y_test = y_test * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(SeqDataset(train, max_len=64, with_yield=True), batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(SeqDataset(val, max_len=64, with_yield=True), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "test_loader = DataLoader(SeqDataset(test, max_len=64, with_yield=True), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta_h256_attn8_drop03 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RoBERTaFineTuner.load_from_checkpoint('...', roberta_model_path='existing_roberta', freeze_roberta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8702be5cd03e4e81a574d1600ae81866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(305.0496, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 305.049560546875}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [[pred.item() for pred in preds] for preds in model.out_predictions]\n",
    "preds_flat = [j for sub in predictions for j in sub]\n",
    "predictions_np = np.array(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255701,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on other temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDatasetTemp(Dataset):\n",
    "    def __init__(self, data, max_len, with_yield=True, col='Yield_37C'):\n",
    "        self.data = pd.DataFrame(data, columns=['Seq1', 'Seq2', col])  # pandas dataframe\n",
    "        self.data[col] = self.data[col] * 100\n",
    "        self.col = col\n",
    "        #Initialize the tokenizer\n",
    "        self.tokenizer = RobertaTokenizerFast.from_pretrained(\"tokenizer\", max_len=64)\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.with_yield = with_yield \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Selecting sequence1 and sequence2 at the specified index in the data frame\n",
    "        seq1 = str(self.data.loc[index, 'Seq1'])\n",
    "        seq2 = str(self.data.loc[index, 'Seq2'])\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_pair = self.tokenizer(seq1, seq2, \n",
    "                                      padding='max_length',         # Pad to max_length\n",
    "                                      truncation=True,              # Truncate to max_length\n",
    "                                      max_length=self.max_len,  \n",
    "                                      return_tensors='pt')          # Return torch.Tensor objects\n",
    "\n",
    "        token_ids = encoded_pair['input_ids'].squeeze(0)            # tensor of token ids\n",
    "        attn_masks = encoded_pair['attention_mask'].squeeze(0)      # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
    "#         token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
    "\n",
    "        if self.with_yield:  # True if the dataset has yields\n",
    "            yld = self.data.loc[index, self.col]\n",
    "            return token_ids.to(device=dev), attn_masks.to(device=dev), yld  \n",
    "        else:\n",
    "            return token_ids.to(device=dev), attn_masks.to(device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tempds_df = pd.read_csv('test_set_other_temperatures.csv')\n",
    "\n",
    "test_dataloader_37 = DataLoader(SeqDatasetTemp(all_tempds_df, max_len=64, with_yield=True, col='Yield_37C'), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "test_dataloader_42 = DataLoader(SeqDatasetTemp(all_tempds_df, max_len=64, with_yield=True, col='Yield_42C'), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "test_dataloader_47 = DataLoader(SeqDatasetTemp(all_tempds_df, max_len=64, with_yield=True, col='Yield_47C'), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "test_dataloader_52 = DataLoader(SeqDatasetTemp(all_tempds_df, max_len=64, with_yield=True, col='Yield_52C'), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "test_dataloader_62 = DataLoader(SeqDatasetTemp(all_tempds_df, max_len=64, with_yield=True, col='Yield_62C'), batch_size=BATCH_SIZE, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.out_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c841bd1b9d4965aa7d3f972a4380ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(546.0577, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c291a199e4a54aaebac06b32d58779f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(452.8763, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b916d09c78d047d59c90235187f567bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(336.5995, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70046529c4b54797b414e58657b306ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(249.7258, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11b540a5e0749faab7a9852ef61506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(674.3285, device='cuda:0', dtype=torch.float32)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for test_loader_temp in [test_dataloader_37, test_dataloader_42, test_dataloader_47, test_dataloader_52, test_dataloader_62]:\n",
    "    trainer_chkp = pl.Trainer(gpus=[0])\n",
    "    trainer_chkp.test(model, test_dataloaders=test_loader_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5994"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.out_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_pt = torch.cat(model.out_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1534206, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = torch.chunk(preds_pt, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_chunk = chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_37 = all_tempds_df['Yield_37C'].values\n",
    "y_test_42 = all_tempds_df['Yield_42C'].values\n",
    "y_test_47 = all_tempds_df['Yield_47C'].values\n",
    "y_test_52 = all_tempds_df['Yield_52C'].values\n",
    "y_test_62 = all_tempds_df['Yield_62C'].values\n",
    "\n",
    "y_test_37 = y_test_37 * 100\n",
    "y_test_42 = y_test_42 * 100\n",
    "y_test_47 = y_test_47 * 100\n",
    "y_test_52 = y_test_52 * 100\n",
    "y_test_62 = y_test_62 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp_all = [y_test_37, y_test_42, y_test_47, y_test_52, y_test_62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC:  0.9253407679688482\n",
      "AUROC:  0.9705506599596415\n",
      "Avg. prec:  0.9776205923831391\n",
      "(array([0.91501096, 0.9948332 ]), array([0.99087445, 0.95022687]), array([0.95143284, 0.97201855]), array([ 89748, 165953], dtype=int64))\n",
      "\n",
      "MCC:  0.929655290644327\n",
      "AUROC:  0.9708993635540727\n",
      "Avg. prec:  0.976416713669797\n",
      "(array([0.92598957, 0.99167886]), array([0.98555549, 0.95624323]), array([0.95484446, 0.97363873]), array([ 91315, 164386], dtype=int64))\n",
      "\n",
      "MCC:  0.9302274897836948\n",
      "AUROC:  0.9680316033740517\n",
      "Avg. prec:  0.97055319800303\n",
      "(array([0.94150573, 0.98292243]), array([0.97126662, 0.96479658]), array([0.95615465, 0.97377516]), array([ 94211, 161490], dtype=int64))\n",
      "\n",
      "MCC:  0.9137365425628989\n",
      "AUROC:  0.9541943687945057\n",
      "Avg. prec:  0.9487468727176351\n",
      "(array([0.96208419, 0.95703164]), array([0.93210387, 0.97628486]), array([0.94685677, 0.96656239]), array([100315, 155386], dtype=int64))\n",
      "\n",
      "MCC:  0.7619331687484813\n",
      "AUROC:  0.8699215552757904\n",
      "Avg. prec:  0.7874826430058636\n",
      "(array([0.99635761, 0.78832517]), array([0.74266804, 0.99717507]), array([0.85100867, 0.88053554]), array([130388, 125313], dtype=int64))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks[1:])):\n",
    "    predictions_labels = [1 if x > 20 else 0 for x in chunks[1:][i]]\n",
    "    true_labels = [1 if x > 20 else 0 for x in y_temp_all[i]]\n",
    "    print('MCC: ', matthews_corrcoef(true_labels, predictions_labels))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, predictions_labels)\n",
    "    print('AUROC: ', auc(fpr, tpr))\n",
    "    print('Avg. prec: ', average_precision_score(true_labels, predictions_labels))\n",
    "    print(precision_recall_fscore_support(true_labels, predictions_labels, average=None))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4475],\n",
       "        [-2.5762],\n",
       "        [-2.1789],\n",
       "        ...,\n",
       "        [99.6723],\n",
       "        [97.8562],\n",
       "        [99.8846]], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1.8-cuda11.1",
   "language": "python",
   "name": "pt1.8-cuda11.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
