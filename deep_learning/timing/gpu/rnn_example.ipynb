{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 26\n",
    "LR = 0.0005974060251967456\n",
    "BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepdish as dd\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from torchnlp.encoders.text import CharacterEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, roc_curve, matthews_corrcoef, plot_confusion_matrix\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRegression(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_size, num_layers, dropout):\n",
    "        super(RNNRegression, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_predictions = []\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.21659149581080556)\n",
    "        \n",
    "        self.linear = nn.Linear(2 * hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x.long())\n",
    "        x, _ = self.rnn(x)\n",
    "        cls_token_emb = x[:, 0, :]\n",
    "        x = self.dropout(cls_token_emb)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        train_out = self(x)\n",
    "        loss = F.mse_loss(torch.squeeze(train_out), y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), LR)\n",
    "    \n",
    "            \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        val_out = self(x)\n",
    "        val_loss = F.mse_loss(torch.squeeze(val_out), y)\n",
    "        self.log('val_loss', val_loss)\n",
    "        return val_loss\n",
    "    \n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        test_out = self(x)\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            list(zip(X_train, y_train)),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    \n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            list(zip(X_val, y_val)),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            list(zip(X_test, y_test)),\n",
    "            batch_size=8192,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dd.io.load('../splits/train.h5')\n",
    "val = dd.io.load('../splits/val.h5')\n",
    "test = dd.io.load('../splits/test.h5')\n",
    "y_train = np.load('../splits/y_train.npy')\n",
    "y_val = np.load('../splits/y_val.npy')\n",
    "y_test = np.load('../splits/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train * 100\n",
    "y_val = y_val * 100\n",
    "y_test = y_test * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = set()\n",
    "all_seqs.update([item[0] for item in train])\n",
    "all_seqs.update([item[1] for item in train])\n",
    "all_seqs.update([item[0] for item in val])\n",
    "all_seqs.update([item[1] for item in val])\n",
    "all_seqs.update([item[0] for item in test])\n",
    "all_seqs.update([item[1] for item in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CharacterEncoder(all_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = dict(zip(encoder.vocab, range(len(encoder.vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.encoders.text.default_reserved_tokens import DEFAULT_SOS_INDEX\n",
    "from torchnlp.encoders.text.default_reserved_tokens import DEFAULT_EOS_INDEX\n",
    "from torchnlp.encoders.text.default_reserved_tokens import DEFAULT_PADDING_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, split):\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "    hist = [[], [], []]\n",
    "    for i, val in enumerate(y):\n",
    "        if val < 0.1:\n",
    "            hist[0].append((X[i], val))\n",
    "        elif val <= 0.90:\n",
    "            hist[1].append((X[i], val))\n",
    "        else:\n",
    "            hist[2].append((X[i], val))\n",
    "            \n",
    "    for h in hist:\n",
    "        np.random.shuffle(h)\n",
    "        limit = int(len(h) * split)\n",
    "        d1, d2 = h[:limit], h[limit:]\n",
    "        for pair in d1:\n",
    "            X_train.append(pair[0])\n",
    "            y_train.append(pair[1])\n",
    "        for pair in d2:\n",
    "            X_test.append(pair[0])\n",
    "            y_test.append(pair[1])\n",
    "            \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_for_rnn(seq, max_len):\n",
    "    # Default padding index is zero for the character encoder\n",
    "    nucl_dict = {'A': enc_dict['A'], 'C': enc_dict['C'], 'G': enc_dict['G'], 'T': enc_dict['T']}\n",
    "    mat = np.zeros(max_len, dtype=int)\n",
    "    \n",
    "    for i, nucl in enumerate(seq):\n",
    "        mat[i] = nucl_dict[nucl]\n",
    "    return mat\n",
    "\n",
    "def encode_pair_for_rnn(seq1, seq2, max_len):\n",
    "    enc1 = encode_for_rnn(seq1, max_len)\n",
    "    enc2 = encode_for_rnn(seq2, max_len)\n",
    "    return np.hstack((np.array([DEFAULT_SOS_INDEX]), enc1, np.array([DEFAULT_EOS_INDEX]), enc2, np.array([DEFAULT_EOS_INDEX])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [encode_pair_for_rnn(item[0], item[1], MAX_LEN) for item in train]\n",
    "X_val = [encode_pair_for_rnn(item[0], item[1], MAX_LEN) for item in val]\n",
    "X_test = [encode_pair_for_rnn(item[0], item[1], MAX_LEN) for item in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=np.dtype('d'))\n",
    "X_val = np.array(X_val, dtype=np.dtype('d'))\n",
    "X_test = np.array(X_test, dtype=np.dtype('d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNRegression(\n",
       "  (embeddings): Embedding(9, 32)\n",
       "  (rnn): LSTM(32, 64, num_layers=3, batch_first=True, dropout=0.2412375022122436, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.21659149581080556, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNRegression.load_from_checkpoint('...', vocab_size=len(encoder.vocab), emb_dim=32, hidden_size=64, num_layers=3, dropout=0.2412375022122436)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ca5d3f5b7f4ca18db6b59b67abb08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "17319.466796875\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 1\n",
    "timings=np.zeros((repetitions,1))\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "        starter.record()\n",
    "        trainer.test(model)\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "mean_syn = np.sum(timings) / repetitions\n",
    "std_syn = np.std(timings)\n",
    "print(mean_syn)\n",
    "print(std_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16214.48828125],\n",
       "       [15779.60449219],\n",
       "       [15781.15527344],\n",
       "       [15978.25976562],\n",
       "       [15781.203125  ],\n",
       "       [16011.27832031],\n",
       "       [15892.85839844],\n",
       "       [16094.82128906],\n",
       "       [16198.18457031],\n",
       "       [15897.16796875]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
